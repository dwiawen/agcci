{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c414ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T04:51:46.843289Z",
     "start_time": "2025-12-27T04:51:42.072702Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/y04tjy6s14j73msn7v4_djm00000gn/T/ipykernel_70472/1285696963.py:289: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  subset = out_df[\n",
      "/var/folders/5t/y04tjy6s14j73msn7v4_djm00000gn/T/ipykernel_70472/1285696963.py:289: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  subset = out_df[\n",
      "/var/folders/5t/y04tjy6s14j73msn7v4_djm00000gn/T/ipykernel_70472/1285696963.py:289: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  subset = out_df[\n",
      "/var/folders/5t/y04tjy6s14j73msn7v4_djm00000gn/T/ipykernel_70472/1285696963.py:289: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  subset = out_df[\n",
      "/var/folders/5t/y04tjy6s14j73msn7v4_djm00000gn/T/ipykernel_70472/1285696963.py:289: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  subset = out_df[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "- Main output: /Users/dwiprabowo/Downloads/greencompactcityurban/screening_output/screened_combined_wos_scopus_threshold_domains.xlsx\n",
      "- Summary:     /Users/dwiprabowo/Downloads/greencompactcityurban/screening_output/screening_summary_counts.xlsx\n",
      "- Per-domain subsets saved to: /Users/dwiprabowo/Downloads/greencompactcityurban/screening_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAfter running:\\n1) Open screened_combined_wos_scopus_threshold_domains.xlsx\\n2) Filter screen_pass_threshold_based = TRUE\\n3) Sort by priority_score\\n4) Manually confirm in PDF/full text that thresholds are explicitly stated and extract:\\n   - indicator name, unit, threshold value, source (WHO/plan code/etc.), scale, context\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Screening code (Python) for threshold/standard-based indicator papers\n",
    "\n",
    "What it does\n",
    "1) Loads the dataset.\n",
    "2) Builds a searchable text field from Title/Abstract/Keywords (robust to column name variants).\n",
    "3) Tags each record into 5 domains:\n",
    "   (1) morphology-density\n",
    "   (2) accessibility-mobility\n",
    "   (3) green & blue infrastructure\n",
    "   (4) land use mix\n",
    "   (5) climate & environmental performance\n",
    "4) Detects whether the paper likely contains explicit indicator thresholds/standards\n",
    "   (e.g., “threshold”, “cut-off”, “benchmark”, “WHO”, “≤ 800 m”, “FAR”, “NDVI ≥ 0.3”, etc.)\n",
    "5) Produces:\n",
    "   - an Excel file with flags, scores, and “hits” (matched terms)\n",
    "   - per-domain subsets (optional)\n",
    "\n",
    "Notes\n",
    "- This is a metadata pre-screening (Title/Abstract/Keywords). You have to validate thresholds in full text.\n",
    "- You can tighten/loosen the lexicon below to match your field.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths\n",
    "# ----------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths (LOCAL MACHINE)\n",
    "# ----------------------------\n",
    "INPUT_XLSX = Path(\n",
    "    \"/Users/dwiprabowo/Downloads/greencompactcityurban/combined_wos_scopus.xlsx\"\n",
    ")\n",
    "\n",
    "OUT_DIR = Path(\n",
    "    \"/Users/dwiprabowo/Downloads/greencompactcityurban/screening_output\"\n",
    ")\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_ALL = OUT_DIR / \"screened_combined_wos_scopus_threshold_domains.xlsx\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Helpers\n",
    "# ----------------------------\n",
    "def _normalize_text(x: object) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x)\n",
    "    s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _find_first_existing_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Find first column whose normalized name matches any candidate.\n",
    "    Candidates should be lowercased.\n",
    "    \"\"\"\n",
    "    cols_norm = {c: re.sub(r\"[^a-z0-9_]+\", \"\", c.lower()) for c in df.columns}\n",
    "    cand_norm = [re.sub(r\"[^a-z0-9_]+\", \"\", c.lower()) for c in candidates]\n",
    "    for c, cn in cols_norm.items():\n",
    "        if cn in cand_norm:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _regex_findall(pattern: re.Pattern, text: str) -> List[str]:\n",
    "    return list({m.group(0) for m in pattern.finditer(text)})  # unique\n",
    "\n",
    "\n",
    "def _compile_any(phrases: List[str], flags=re.IGNORECASE) -> re.Pattern:\n",
    "    # Escape phrases unless they already look like regex (contain \\b, [], (), etc.)\n",
    "    parts = []\n",
    "    for p in phrases:\n",
    "        if any(ch in p for ch in [r\"\\b\", \"[\", \"]\", \"(\", \")\", \"|\", \"+\", \"*\", \"?\", \"{\", \"}\", \"^\", \"$\"]):\n",
    "            parts.append(p)\n",
    "        else:\n",
    "            parts.append(re.escape(p))\n",
    "    return re.compile(r\"(\" + r\"|\".join(parts) + r\")\", flags)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Lexicon (EDIT HERE)\n",
    "# ----------------------------\n",
    "DOMAIN_TERMS: Dict[str, List[str]] = {\n",
    "    # 1) Morphology–Density\n",
    "    \"morphology_density\": [\n",
    "        r\"\\bcompact city\\b\", r\"\\burban form\\b\", r\"\\bmorpholog(y|ical)\\b\", r\"\\bdensit(y|ies)\\b\",\n",
    "        r\"\\bfloor area ratio\\b\", r\"\\bFAR\\b\", r\"\\bFSI\\b\", r\"\\bplot ratio\\b\", r\"\\bGSI\\b\", r\"\\bBCR\\b\",\n",
    "        r\"\\bbuilding height\\b\", r\"\\bhigh[- ]rise\\b\", r\"\\bmid[- ]rise\\b\", r\"\\blow[- ]rise\\b\",\n",
    "        r\"\\bdwelling(s)? per hectare\\b\", r\"\\bDU/?ha\\b\", r\"\\bpopulation density\\b\", r\"\\bnet density\\b\",\n",
    "        r\"\\bintersection density\\b\", r\"\\bcompactness index\\b\", r\"\\bsprawl\\b\", r\"\\bfragmentation\\b\",\n",
    "    ],\n",
    "\n",
    "    # 2) Accessibility–Mobility\n",
    "    \"accessibility_mobility\": [\n",
    "        r\"\\baccessibilit(y|ies)\\b\", r\"\\bwalkabilit(y|ies)\\b\", r\"\\bwalkable\\b\", r\"\\bwalk[- ]?shed\\b\",\n",
    "        r\"\\bpublic transport\\b\", r\"\\btransit\\b\", r\"\\bPTAL\\b\", r\"\\bcatchment\\b\", r\"\\bservice area\\b\",\n",
    "        r\"\\btravel time\\b\", r\"\\bcommut(e|ing)\\b\", r\"\\bmodal share\\b\", r\"\\bactive travel\\b\",\n",
    "        r\"\\bconnectivit(y|ies)\\b\", r\"\\bstreet network\\b\", r\"\\bintersection\\b\", r\"\\b15[- ]minute city\\b\",\n",
    "        r\"\\b400\\s?m\\b\", r\"\\b800\\s?m\\b\", r\"\\b10\\s?min(ute)?\\b\", r\"\\b15\\s?min(ute)?\\b\",\n",
    "    ],\n",
    "\n",
    "    # 3) Green & Blue Infrastructure\n",
    "    \"green_blue_infra\": [\n",
    "        r\"\\bgreen space(s)?\\b\", r\"\\burban green\\b\", r\"\\burban park(s)?\\b\", r\"\\bgreen infrastruct(ure|ures)\\b\",\n",
    "        r\"\\bblue[- ]green\\b\", r\"\\bblue space(s)?\\b\", r\"\\bwater bod(y|ies)\\b\", r\"\\briver(s)?\\b\",\n",
    "        r\"\\blake(s)?\\b\", r\"\\bwetland(s)?\\b\", r\"\\bcoast(al)?\\b\", r\"\\bcanopy\\b\", r\"\\btrees?\\b\",\n",
    "        r\"\\bNDVI\\b\", r\"\\bEVI\\b\", r\"\\bvegetation\\b\", r\"\\becosystem service(s)?\\b\",\n",
    "        r\"\\bper capita green\\b\", r\"\\bm2\\/capita\\b\", r\"\\bm²\\/capita\\b\",\n",
    "    ],\n",
    "\n",
    "    # 4) Land Use Mix\n",
    "    \"land_use_mix\": [\n",
    "        r\"\\bland use\\b\", r\"\\bland[- ]use\\b\", r\"\\bmixed[- ]use\\b\", r\"\\bland use mix\\b\",\n",
    "        r\"\\bentropy\\b\", r\"\\bShannon\\b\", r\"\\bdiversit(y|ies)\\b\", r\"\\bfunctional mix\\b\",\n",
    "        r\"\\bMXI\\b\", r\"\\bjob[- ]housing balance\\b\", r\"\\bLUM\\b\", r\"\\bzoning\\b\",\n",
    "        r\"\\bresidential\\b\", r\"\\bcommercial\\b\", r\"\\bindustrial\\b\", r\"\\bamenit(y|ies)\\b\",\n",
    "    ],\n",
    "\n",
    "    # 5) Climate & Environmental Performance\n",
    "    \"climate_env_performance\": [\n",
    "        r\"\\burban heat island\\b\", r\"\\bUHI\\b\", r\"\\bland surface temperature\\b\", r\"\\bLST\\b\",\n",
    "        r\"\\blocal climate zone\\b\", r\"\\bLCZ\\b\", r\"\\bthermal\\b\", r\"\\bheat stress\\b\",\n",
    "        r\"\\bmitigation\\b\", r\"\\bcooling\\b\", r\"\\bcooling effect\\b\", r\"\\benergy efficien(t|cy)\\b\",\n",
    "        r\"\\benergy consumption\\b\", r\"\\bemission(s)?\\b\", r\"\\bcarbon\\b\", r\"\\bCO2\\b\",\n",
    "        r\"\\bPM2\\.5\\b\", r\"\\bair quality\\b\", r\"\\bflood\\b\", r\"\\bstormwater\\b\", r\"\\bresilien(ce|t)\\b\",\n",
    "        r\"\\bperformance\\b\", r\"\\benvironmental performance\\b\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# “Threshold / Standard” detectors (you can add local policy names, regs, codes)\n",
    "THRESHOLD_TERMS = [\n",
    "    r\"\\bthreshold(s)?\\b\", r\"\\bcut[- ]?off\\b\", r\"\\bcutoff\\b\", r\"\\bbenchmark(s)?\\b\",\n",
    "    r\"\\bstandard(s)?\\b\", r\"\\bguideline(s)?\\b\", r\"\\bcriteria\\b\", r\"\\bnorm(s)?\\b\",\n",
    "    r\"\\brecommended\\b\", r\"\\btarget(s)?\\b\", r\"\\bminimum\\b\", r\"\\bmaximum\\b\",\n",
    "    r\"\\blimit(s)?\\b\", r\"\\brange\\b\", r\"\\bclassified as\\b\", r\"\\bclassification\\b\",\n",
    "    r\"\\bWHO\\b\", r\"\\bUN[- ]?Habitat\\b\", r\"\\bLEED\\b\", r\"\\bBREEAM\\b\",\n",
    "    r\"\\bISO\\b\", r\"\\bEN\\s?\\d+\\b\",\n",
    "]\n",
    "\n",
    "# Numeric inequality / threshold patterns (captures things like \">= 0.3\", \"≤800 m\", \"FAR > 2.0\")\n",
    "NUMERIC_THRESHOLD_PATTERNS = [\n",
    "    r\"(>=|≤|>=|=>|>|<|≤=|=<)\\s*\\d+(\\.\\d+)?\\s*(%|m|km|ha|m2|m²|°c|c|k|w\\/m2|w\\/m²|mj|kwh|kWh|du\\/ha)?\\b\",\n",
    "    r\"\\b\\d+(\\.\\d+)?\\s*(%|m|km|min|minute|minutes|ha|m2|m²|°c|°C|kwh|kWh)\\s*(or\\s*less|or\\s*more|maximum|minimum)\\b\",\n",
    "    r\"\\bwithin\\s+\\d+(\\.\\d+)?\\s*(m|km|min|minutes)\\b\",\n",
    "]\n",
    "\n",
    "# Optional: method cues that often co-occur with operational thresholds (not required)\n",
    "METHOD_CUES = [\n",
    "    r\"\\bindex\\b\", r\"\\bindicator(s)?\\b\", r\"\\bscor(e|ing)\\b\", r\"\\bcomposite\\b\",\n",
    "    r\"\\bGIS\\b\", r\"\\bremote sensing\\b\", r\"\\bsatellite\\b\", r\"\\bspatial metric(s)?\\b\",\n",
    "    r\"\\bmachine learning\\b\", r\"\\bdeep learning\\b\", r\"\\brandom forest\\b\",\n",
    "]\n",
    "\n",
    "\n",
    "# Compile regex\n",
    "DOMAIN_RE = {k: _compile_any(v) for k, v in DOMAIN_TERMS.items()}\n",
    "THRESHOLD_RE = _compile_any(THRESHOLD_TERMS)\n",
    "METHOD_RE = _compile_any(METHOD_CUES)\n",
    "NUMERIC_RE_LIST = [re.compile(p, re.IGNORECASE) for p in NUMERIC_THRESHOLD_PATTERNS]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Load dataset\n",
    "# ----------------------------\n",
    "df = pd.read_excel(INPUT_XLSX)\n",
    "\n",
    "# Identify main metadata columns robustly\n",
    "title_col = _find_first_existing_col(df, [\"ti\", \"title\"])\n",
    "abs_col = _find_first_existing_col(df, [\"ab\", \"abstract\"])\n",
    "# Keywords can be in several bibliometrix fields\n",
    "kw_cols = []\n",
    "for c in df.columns:\n",
    "    cn = re.sub(r\"[^a-z0-9_]+\", \"\", c.lower())\n",
    "    if cn in {\"de\", \"id\", \"keywords\", \"authorkeywords\", \"keywordplus\", \"kw\", \"kw_merged\", \"kwmerged\"}:\n",
    "        kw_cols.append(c)\n",
    "\n",
    "doi_col = _find_first_existing_col(df, [\"di\", \"doi\"])\n",
    "\n",
    "# Create searchable text\n",
    "df[\"_title\"] = df[title_col].map(_normalize_text) if title_col else \"\"\n",
    "df[\"_abstract\"] = df[abs_col].map(_normalize_text) if abs_col else \"\"\n",
    "if kw_cols:\n",
    "    df[\"_keywords\"] = df[kw_cols].astype(str).fillna(\"\").agg(\" ; \".join, axis=1).map(_normalize_text)\n",
    "else:\n",
    "    df[\"_keywords\"] = \"\"\n",
    "\n",
    "df[\"_search_text\"] = (\n",
    "    df[\"_title\"].str.lower() + \" \" + df[\"_abstract\"].str.lower() + \" \" + df[\"_keywords\"].str.lower()\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Tag domains + threshold evidence\n",
    "# ----------------------------\n",
    "def detect_numeric_thresholds(text: str) -> List[str]:\n",
    "    hits = []\n",
    "    for rnum in NUMERIC_RE_LIST:\n",
    "        hits.extend(_regex_findall(rnum, text))\n",
    "    return list({h.strip() for h in hits if h.strip()})\n",
    "\n",
    "\n",
    "def detect_hits(pattern: re.Pattern, text: str) -> List[str]:\n",
    "    return _regex_findall(pattern, text)\n",
    "\n",
    "\n",
    "# Domain flags + hits\n",
    "for domain, pat in DOMAIN_RE.items():\n",
    "    df[f\"flag_{domain}\"] = df[\"_search_text\"].apply(lambda t: bool(pat.search(t)))\n",
    "    df[f\"hits_{domain}\"] = df[\"_search_text\"].apply(lambda t: \"; \".join(detect_hits(pat, t))[:2000])\n",
    "\n",
    "# Threshold evidence\n",
    "df[\"flag_threshold_terms\"] = df[\"_search_text\"].apply(lambda t: bool(THRESHOLD_RE.search(t)))\n",
    "df[\"hits_threshold_terms\"] = df[\"_search_text\"].apply(lambda t: \"; \".join(detect_hits(THRESHOLD_RE, t))[:2000])\n",
    "\n",
    "df[\"hits_numeric_thresholds\"] = df[\"_search_text\"].apply(lambda t: \"; \".join(detect_numeric_thresholds(t))[:2000])\n",
    "df[\"flag_numeric_thresholds\"] = df[\"hits_numeric_thresholds\"].str.len().gt(0)\n",
    "\n",
    "# Method cue (optional)\n",
    "df[\"flag_method_cues\"] = df[\"_search_text\"].apply(lambda t: bool(METHOD_RE.search(t)))\n",
    "df[\"hits_method_cues\"] = df[\"_search_text\"].apply(lambda t: \"; \".join(detect_hits(METHOD_RE, t))[:2000])\n",
    "\n",
    "# A simple “screening score”\n",
    "domain_flags = [c for c in df.columns if c.startswith(\"flag_\") and c not in {\"flag_threshold_terms\", \"flag_numeric_thresholds\", \"flag_method_cues\"}]\n",
    "df[\"n_domains_hit\"] = df[domain_flags].sum(axis=1)\n",
    "\n",
    "# Core screening rule (EDIT):\n",
    "# - Must hit >=1 domain AND (threshold_terms OR numeric_thresholds)\n",
    "df[\"screen_pass_threshold_based\"] = (df[\"n_domains_hit\"] >= 1) & (df[\"flag_threshold_terms\"] | df[\"flag_numeric_thresholds\"])\n",
    "\n",
    "# Optional stricter rule:\n",
    "# - Must hit >=1 domain AND numeric threshold evidence (e.g., >=, ≤, “within 400 m”)\n",
    "df[\"screen_pass_numeric_only\"] = (df[\"n_domains_hit\"] >= 1) & (df[\"flag_numeric_thresholds\"])\n",
    "\n",
    "# A combined priority score to sort candidates:\n",
    "# +3 if numeric thresholds present\n",
    "# +2 if threshold terms present\n",
    "# +1 if method cues present\n",
    "# + (domains hit)\n",
    "df[\"priority_score\"] = (\n",
    "    df[\"n_domains_hit\"].astype(int)\n",
    "    + 3 * df[\"flag_numeric_thresholds\"].astype(int)\n",
    "    + 2 * df[\"flag_threshold_terms\"].astype(int)\n",
    "    + 1 * df[\"flag_method_cues\"].astype(int)\n",
    ")\n",
    "\n",
    "# Keep a compact view for review\n",
    "keep_cols = []\n",
    "for c in [doi_col, title_col, abs_col] + kw_cols:\n",
    "    if c and c in df.columns and c not in keep_cols:\n",
    "        keep_cols.append(c)\n",
    "\n",
    "keep_cols += (\n",
    "    domain_flags\n",
    "    + [\"n_domains_hit\", \"flag_threshold_terms\", \"flag_numeric_thresholds\", \"flag_method_cues\",\n",
    "       \"screen_pass_threshold_based\", \"screen_pass_numeric_only\", \"priority_score\"]\n",
    "    + [f\"hits_{d}\" for d in DOMAIN_RE.keys()]\n",
    "    + [\"hits_threshold_terms\", \"hits_numeric_thresholds\", \"hits_method_cues\"]\n",
    ")\n",
    "\n",
    "out_df = df[keep_cols].copy()\n",
    "\n",
    "# Sort for manual screening workflow\n",
    "out_df = out_df.sort_values(by=[\"screen_pass_threshold_based\", \"priority_score\"], ascending=[False, False])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Export outputs\n",
    "# ----------------------------\n",
    "out_df.to_excel(OUT_ALL, index=False)\n",
    "\n",
    "# Optional: per-domain subsets for convenience\n",
    "for domain in DOMAIN_RE.keys():\n",
    "    subset = out_df[\n",
    "        (df[f\"flag_{domain}\"]) & (df[\"screen_pass_threshold_based\"])\n",
    "    ].copy()\n",
    "    subset_path = OUT_DIR / f\"subset_{domain}_threshold_based.xlsx\"\n",
    "    subset.to_excel(subset_path, index=False)\n",
    "\n",
    "# Summary counts\n",
    "summary = {\n",
    "    \"total_records\": len(df),\n",
    "    \"pass_threshold_based\": int(df[\"screen_pass_threshold_based\"].sum()),\n",
    "    \"pass_numeric_only\": int(df[\"screen_pass_numeric_only\"].sum()),\n",
    "}\n",
    "for domain in DOMAIN_RE.keys():\n",
    "    summary[f\"pass_{domain}_threshold_based\"] = int(((df[f\"flag_{domain}\"]) & (df[\"screen_pass_threshold_based\"])).sum())\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_path = OUT_DIR / \"screening_summary_counts.xlsx\"\n",
    "summary_df.to_excel(summary_path, index=False)\n",
    "\n",
    "print(\"DONE\")\n",
    "print(f\"- Main output: {OUT_ALL}\")\n",
    "print(f\"- Summary:     {summary_path}\")\n",
    "print(f\"- Per-domain subsets saved to: {OUT_DIR}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After running:\n",
    "1) Open screened_combined_wos_scopus_threshold_domains.xlsx\n",
    "2) Filter screen_pass_threshold_based = TRUE\n",
    "3) Sort by priority_score\n",
    "4) Manually confirm in PDF/full text that thresholds are explicitly stated and extract:\n",
    "   - indicator name, unit, threshold value, source (WHO/plan code/etc.), scale, context\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f91f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "env_slr",
   "language": "python",
   "name": "env_slr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
